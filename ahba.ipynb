{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching AHBA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abagen\n",
    "from abagen import reporting\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain data from all available donors, pass in ```donors='all'``` instead of a donor list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = abagen.fetch_microarray(donors=['9861', '10021'], verbose=0, data_dir='./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading AHBA Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See the Reference API on [abagen.io](https://abagen.readthedocs.io/en/latest/api.html#module-abagen.io) for a comprehensive list of functions that assist with loading ABHA data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List donor ID keys\n",
    "print(files.keys())\n",
    "\n",
    "# List the downloaded files available for donor 9861\n",
    "sorted(files['9861'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the annotation for donor 9861\n",
    "data = files['9861']\n",
    "annotation = abagen.io.read_annotation(data['annotation'])\n",
    "annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the probes for donor 9861\n",
    "probes = abagen.io.read_probes(data['probes'])\n",
    "probes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parcellations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo Parcellation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```abagen.fetch_desikan_killiany``` will return a dictionary with two keys: \n",
    "1. ```image```: Filepath to a NIFTI image containing the atlas data.\n",
    "2. ```info```: Filepath to a CSV file containing extra parcellation info.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas = abagen.fetch_desikan_killiany()\n",
    "\n",
    "im = nib.load(atlas['image'])\n",
    "\n",
    "# Image type should be a 'nibabel.nifti1.Nifti1Image'\n",
    "# print(type(im))\n",
    "\n",
    "# View metadata\n",
    "# print(im.header)\n",
    "\n",
    "# Get the shape of the numpy array\n",
    "im_data = im.get_fdata()\n",
    "print(im_data.shape)\n",
    "\n",
    "for i in range(10, len(im_data), 20):\n",
    "    plt.imshow(im_data[i], cmap=\"bone\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individualized Parcellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas = abagen.fetch_desikan_killiany(native=True)\n",
    "\n",
    "for key in atlas['image']:\n",
    "    im = nib.load(atlas['image'][key])\n",
    "    im_data = im.get_fdata()\n",
    "    print(f\"Donor {key}\")\n",
    "    plt.imshow(im_data[100], cmap=\"bone\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parcellating Expression Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See the [abagen docs](https://abagen.readthedocs.io/en/latest/user_guide/expression.html) for more information on parcellating expression data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_expression_data assigns [microarray](https://www.youtube.com/watch?v=NgRfc6atXQ8) gene expression data to the ROIs defined in the atlas['img'] argument. For our purposes, this is the Allen Human Brain atlas for each donor.\n",
    "\n",
    "Matching of microarray samples to parcels in atlas is done via a [multi-step process](https://abagen.readthedocs.io/en/stable/generated/abagen.get_expression_data.html):\n",
    "1. Determine if the sample falls directly within a parcel.\n",
    "\n",
    "2. Check to see if there are nearby parcels by slowly expanding the search space to include nearby voxels, up to a specified distance (specified via the tolerance parameter).\n",
    "\n",
    "3. If there are multiple nearby parcels, the sample is assigned to the closest parcel, as determined by the parcel centroid.\n",
    "\n",
    "By default, data are normalized using a scaled robust [sigmoid function](https://en.wikipedia.org/wiki/Sigmoid_function) such that the expression values for a given gene will range from 0-1.\n",
    "A value of 0 indicates the region with the lowest gene expression, while a value of 1 indicates the region with the highest.\n",
    "\n",
    "Note that the generated pandas.DataFrame is an aggregate of the donor argument/s.\n",
    "\n",
    "Interpreting the DataFrame:\n",
    "- DataFrame rows correspond to region labels as defined in the atlas image.\n",
    "- DataFrame columns correspond to genes.\n",
    "- Entry values are microarray expression data normalized and aggregated across selected donors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all donor image data\n",
    "# expression = abagen.get_expression_data(atlas['image'])\n",
    "\n",
    "# When using a volumetric image, it is recommended to include the additional information on the parcellation\n",
    "# Note that the following function call loads all our specified donor data into memory, and will therefore be quite time-consuming\n",
    "expression = abagen.get_expression_data(atlas['image'], atlas['info'], donors=['9861', '10021'])\n",
    "\n",
    "expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that some regions may not be matched to any tissue samples\n",
    "nan_rows = expression.isna().any(axis=1)\n",
    "\n",
    "for row, is_nan in nan_rows.items():\n",
    "    if (is_nan):\n",
    "        print(row, is_nan)\n",
    "\n",
    "expression.loc[[18, 45]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensuring a Dense Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Microarray expression data may be missing (especially in right hemisphere regions), since not all donors have tissue samples for these areas.\n",
    "\n",
    "abagen.get_expression_data() takes the following steps for each tissue sample:\n",
    "\n",
    "1. Determine if the sample falls directly within a region of ```atlas```.\n",
    "2. Check to see if the sample is close to any regions by slowly expanding the search space to include nearby voxels up to a particular threshold (specified using the ```tolerance``` parameter).\n",
    "3. If there are multiple nearby regions, determine which region is closer by calculating the center-of-mass of the abutting reions.\n",
    "\n",
    "Regions with no samples will have entry values of NaN. \n",
    "To resolve some/all empty entry values, we can utilize the two following techniques:\n",
    "1. Use the ```missing``` parameter for localized data filling.\n",
    "2. Duplicate samples across the main brain hemispheres with the ```lr_mirror``` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using the ```missing``` Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```missing``` parameter accepts three options:\n",
    "1. ```None``` (default)\n",
    "2. ```centroids```: Empty regions in the atlas will be assigned the expression values of the tissue sample falling closest to the centroid of that region. This is only done when all donors are missing data for a particular region. A weighted average of the matched samples are taken across donors, where the weights are calculated as the inverse distance between the tissue sample matched to the parcel centroid for each donor.\n",
    "3. ```interpolate```: Expression values will be interpolated in the empty regions by assigning every node in the region the expression of the nearest tissue sample. This interpolation is done independently for every donor, irrespective of whether other donors have tissue samples that fall within a given region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the missing parameter will guarantee a dense expression matrix from an abagen.get_expression_data() function call\n",
    "exp_centroids = abagen.get_expression_data(atlas['image'], atlas['info'], donors=['9861', '10021'], missing='centroids')\n",
    "\n",
    "# Note that our NaN values have now been replaced with the nearest tissue expression values\n",
    "exp_centroids.loc[[18, 45]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Duplicating Samples with the ```lr_mirror``` Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most regions in the left hemisphere are likely to be matched to at least one sample, while right-hemisphere regions are less likely. The ```lr_mirror``` parameter allows samples to be mirrored acorss the left/right hemisphere axis. \n",
    "The following four options are available for ```lr_mirror```:\n",
    "1. ```None``` (default)\n",
    "2. ```bidirectional```: All available samples from the left hemisphere are duplicated and mirrored to the right, and vice-versa from right to left.\n",
    "3. ```leftright```: Mirror only the left hemisphere to the right.\n",
    "4. ```rightleft```: Mirror only the right hemisphere to the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lr_mirror sample will not guarantee a dense matrix and will change the expression values of all regions, \n",
    "# not just those that are missing data\n",
    "exp_mirror = abagen.get_expression_data(atlas['image'], atlas['info'], donors=['9861', '10021'], lr_mirror=\"bidirectional\")\n",
    "\n",
    "exp_mirror.loc[[18, 45]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probe Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probes can index the same gene, thereby causing redundant AHBA data. Probes can be selected and condensed to resolve redundancy using the ```probe_selection``` argument.\n",
    "```probe_selection``` contains eight total options, though the ```differential stability``` (default) option is recommended by the official [abagen docs](https://abagen.readthedocs.io/en/stable/user_guide/probes.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting a Representative Probe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following methods select a single probe from each redundant group, based off a specific selection criteria:\n",
    "- ```max_intensity```: Select the probe with the highest average expression across all samples.\n",
    "- ```max_variability```: Select the probe with the highest variance in expression across all samples.\n",
    "- ```pc_loading```: Select the probe with the highest loading value on the first principle component derived from the probe microarray expression.\n",
    "- ```corr_intensity```: Select the probe with the highest correlation to other probes across all samples, using ```max_intensity``` as a fallback in the case of exactly two probes.\n",
    "- ```corr_variance```: Select the probe with the highest correlation to other probes across all samples, using ```max_variance``` as a fallback in the case of exactly two probes.\n",
    "- ```diff_stability```: Compute the [Spearman correlation](https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient) of microarray expression values for each probe across brain regions for every pair of donors. The probe with the highest average correlation is selected.\n",
    "- ```rnaseq```: Compute the Spearman correlation of microarray expression values for each probe across brain regions with RNAseq data for the corresponding gene. Only applies to RNAseq data donors 9861 and 10021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of representative probe selection\n",
    "exp_pc_load = abagen.get_expression_data(atlas['image'], probe_selection='pc_loading')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collapsing Across Probes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An average for all probe expression values can be taken using the ```average``` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_pc_load = abagen.get_expression_data(atlas['image'], probe_selection='average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Donor Aggregation with Probe Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, probe selection is performed using aggregated data across all donor samples. Donor-specific probe selection can be performed using the ```donor_probes``` argument, which takes the following three options:\n",
    "1. ```aggregate```: Aggregate tissue samples across all donors and apply the selected ```probe_selection``` method to the aggregate sample matrix.\n",
    "2. ```independent```: Perform the chosen ```probe_selection``` method for each donor seperately. Cannot be used with ```diff_stability```, ```rnaseq```, or ```average```.\n",
    "3. ```common```: Perform the chosen ```probe_selection``` method for each donor, then use the most commonly-selected probe to represent each gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_cmn_rna = abagen.get_expression_data(atlas['image'], donor_probes='common', probe_selection='rnaseq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The abagen library supports nine options for dataset normalization, though the default ```scaled_robust_sigmoid``` option is recommended by the official [abagen docs](https://abagen.readthedocs.io/en/stable/user_guide/normalization.html). Data normalization options are as follows:\n",
    "1. Centering: ```center```\n",
    "2. Z-score: ```zscore```\n",
    "3. Min-max: ```minmax```\n",
    "4. Sigmoid: ```sigmoid```\n",
    "5. Scaled Sigmoid: ```scaled_sigmoid```\n",
    "6. Scaled Sigmoid Quantiles: ```scaled_sigmoid_quantiles```\n",
    "7. Robust Sigmoid: ```robust_sigmoid```\n",
    "8. Scaled Robust Sigmoid: ```scaled_robust_sigmoid```\n",
    "9. Mixed Sigmoid: ```mixed_sigmoid```\n",
    "\n",
    "Providing a value of ```None``` prevents data normalization.\n",
    "\n",
    "Normalization can be accomplished in two directions: \n",
    "1. Each sample can be normalized across all genes (```gene_norm```).\n",
    "2. Each sample can be normalized across all samples (```sample_norm```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use z-score normalization across all samples\n",
    "exp_norm_zscore = abagen.get_expression_data(atlas['image'], sample_norm='zscore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the selected parameters, abagen can generate a report that details each processing step done to the AHBA dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = reporting.Report(atlas['image'], atlas['info']).gen_report()\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = abagen.fetch_microarray(donors='all', data_dir='./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each donor file contains a probe count of 352,152\n",
    "for donor in files:\n",
    "    print(f\"Donor {donor} probe count: {abagen.io.read_probes(files[donor]['probes']).size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA & Clustering Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section performs dimensionality reduction using the region labels as features. For feature reduction with respect to the genes, see the section titled 'Gene Expression PCA & Clustering'. See the following [365 Data Science](https://365datascience.com/tutorials/python-tutorials/pca-k-means/) guide for more information regarding PCA-based clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brain Region PCA & Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas = abagen.fetch_desikan_killiany()\n",
    "expression = abagen.get_expression_data(atlas['image'], atlas['info'], donors=['9861', '10021'], missing='centroids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot two brain regions with respect to one another\n",
    "# Each data point corresponds to a parcellation\n",
    "plt.figure(figsize=(12, 9))\n",
    "plt.scatter(expression.iloc[1], expression.iloc[0])\n",
    "plt.xlabel('Brain Region 2')\n",
    "plt.ylabel('Brain Region 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In PCA, the columns represent the features, so we need to take the transpose of expression\n",
    "expression_t = expression.transpose()\n",
    "expression_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "expression_std = scaler.fit_transform(expression_t)\n",
    "expression_std.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(expression_t)\n",
    "# Determines how much variance among genes is explained by each brain region\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1, 84), pca.explained_variance_ratio_.cumsum(), marker='o', linestyle='--')\n",
    "plt.title('Explained Variance by Components (Brain Regions)')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Explained Variance (Cumulative)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'd like to capture ~80% of our variance, so we'll keep six components\n",
    "pca = PCA(n_components = 6)\n",
    "pca.fit(expression_std)\n",
    "scores_pca = pca.transform(expression_std)\n",
    "\n",
    "# Fit K-Means using PCA data\n",
    "wcss = []\n",
    "\n",
    "N_CLUSTERS = 20\n",
    "for i in range(1, N_CLUSTERS + 1):\n",
    "    kmeans_pca = KMeans(n_clusters = i, init = 'k-means++', random_state = 21)\n",
    "    kmeans_pca.fit(scores_pca)\n",
    "    wcss.append(kmeans_pca.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 8))\n",
    "plt.plot(range(1, N_CLUSTERS + 1), wcss, marker = 'o', linestyle = '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the graph above, we'd like to keep three clusters (see Elbow Method for K-means Clustering)\n",
    "N_CLUSTERS = 10\n",
    "kmeans_pca = KMeans(n_clusters = N_CLUSTERS, init='k-means++', random_state = 21)\n",
    "kmeans_pca.fit(scores_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data frame with the original features and add the PCA scores and assigned clusters\n",
    "exp_pca_kmeans = pd.concat([expression_t.reset_index(drop = True), pd.DataFrame(scores_pca)], axis = 1)\n",
    "labels = [i for i in range(0, len(expression_t.columns))] + ['Component 1', 'Component 2', 'Component 3', 'Component 4', 'Component 5', 'Component 6']\n",
    "exp_pca_kmeans.columns = labels\n",
    "\n",
    "# Add the PCA K-means Clustering labels\n",
    "exp_pca_kmeans['Expression K-Means PCA'] = kmeans_pca.labels_\n",
    "exp_pca_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_pca_kmeans['Expression'] = exp_pca_kmeans['Expression K-Means PCA'].map({0:'first', 1:'second', 2:'third', 3:'fourth', 4:'fifth', 5:'sixth', 6:'seventh', 7:'eighth', 8:'ninth', 9:'tenth'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data using the two PCA components with largest variance\n",
    "x_axis = exp_pca_kmeans['Component 1']\n",
    "y_axis = exp_pca_kmeans['Component 2']\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x = x_axis, y = y_axis, hue = exp_pca_kmeans['Expression'])\n",
    "plt.title('Gene Clusters by PCA Components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene Expression PCA & Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas = abagen.fetch_desikan_killiany()\n",
    "expression = abagen.get_expression_data(atlas['image'], atlas['info'], donors=['9861', '10021'], missing='centroids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "expression_std = scaler.fit_transform(expression)\n",
    "expression_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(expression)\n",
    "# Determines how much variance among brain regions is expressed by the 83 most variable genes,\n",
    "# since n_components == min(n_samples, n_features)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(range(0, 83), pca.explained_variance_ratio_.cumsum(), marker='o', linestyle='--')\n",
    "plt.title('Explained Variance by Components (Genes)')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Explained Variance (Cumulative)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For ~80% of our variance, we'll keep eight components\n",
    "pca_80 = PCA(n_components = 8)\n",
    "pca_80.fit(expression_std)\n",
    "# For ~50% of our variance, we'll keep two components\n",
    "pca_50 = PCA(n_components = 2)\n",
    "pca_50.fit(expression_std)\n",
    "# For ~40% of our variance, we'll keep one component\n",
    "pca_40 = PCA(n_components = 1)\n",
    "pca_40.fit(expression_std)\n",
    "\n",
    "scores_pca_80 = pca_80.transform(expression_std)\n",
    "scores_pca_50 = pca_50.transform(expression_std)\n",
    "scores_pca_40 = pca_40.transform(expression_std)\n",
    "\n",
    "# Fit K-Means using PCA data\n",
    "wcss_80 = []\n",
    "wcss_50 = []\n",
    "wcss_40 = []\n",
    "\n",
    "N_CLUSTERS = 20\n",
    "for i in range(1, N_CLUSTERS + 1):\n",
    "    kmeans_pca_80 = KMeans(n_clusters = i, init = 'k-means++', random_state = 64)\n",
    "    kmeans_pca_80.fit(scores_pca_80)\n",
    "    wcss_80.append(kmeans_pca_80.inertia_)\n",
    "\n",
    "    kmeans_pca_50 = KMeans(n_clusters = i, init = 'k-means++', random_state = 64)\n",
    "    kmeans_pca_50.fit(scores_pca_50)\n",
    "    wcss_50.append(kmeans_pca_50.inertia_)\n",
    "\n",
    "    kmeans_pca_40 = KMeans(n_clusters = i, init = 'k-means++', random_state = 64)\n",
    "    kmeans_pca_40.fit(scores_pca_40)\n",
    "    wcss_40.append(kmeans_pca_40.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 8))\n",
    "plt.plot(range(1, N_CLUSTERS + 1), wcss_80, marker = 'o', linestyle = '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLUSTERS_80 = 10\n",
    "kmeans_pca_80 = KMeans(n_clusters = N_CLUSTERS_80, init='k-means++', random_state = 21)\n",
    "kmeans_pca_80.fit(scores_pca_80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 8))\n",
    "plt.plot(range(1, N_CLUSTERS + 1), wcss_50, marker = 'o', linestyle = '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLUSTERS_50 = 10\n",
    "kmeans_pca_50 = KMeans(n_clusters = N_CLUSTERS_50, init='k-means++', random_state = 21)\n",
    "kmeans_pca_50.fit(scores_pca_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 8))\n",
    "plt.plot(range(1, N_CLUSTERS + 1), wcss_40, marker = 'o', linestyle = '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLUSTERS_40 = 7\n",
    "kmeans_pca_40 = KMeans(n_clusters = N_CLUSTERS_40, init='k-means++', random_state = 21)\n",
    "kmeans_pca_40.fit(scores_pca_40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_pca_kmeans_80 = pd.concat([expression.reset_index(drop = True), pd.DataFrame(scores_pca_80)], axis = 1)\n",
    "labels = [i for i in range(0, len(expression.columns))] + ['Component 1', 'Component 2', 'Component 3', 'Component 4', 'Component 5', 'Component 6', 'Component 7', 'Component 8']\n",
    "exp_pca_kmeans_80.columns = labels\n",
    "\n",
    "# Add the PCA K-means Clustering labels\n",
    "exp_pca_kmeans_80['Expression K-Means PCA'] = kmeans_pca_80.labels_\n",
    "exp_pca_kmeans_80\n",
    "\n",
    "exp_pca_kmeans_80['Expression'] = exp_pca_kmeans_80['Expression K-Means PCA'].map({0:'first', 1:'second', 2:'third', 3:'fourth', 4:'fifth', 5:'sixth', 6:'seventh', 7:'eighth', 8:'ninth', 9:'tenth'})\n",
    "exp_pca_kmeans_80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_pca_kmeans_50 = pd.concat([expression.reset_index(drop = True), pd.DataFrame(scores_pca_50)], axis = 1)\n",
    "labels = [i for i in range(0, len(expression.columns))] + ['Component 1', 'Component 2']\n",
    "exp_pca_kmeans_50.columns = labels\n",
    "\n",
    "# Add the PCA K-means Clustering labels\n",
    "exp_pca_kmeans_50['Expression K-Means PCA'] = kmeans_pca_50.labels_\n",
    "exp_pca_kmeans_50\n",
    "\n",
    "exp_pca_kmeans_50['Expression'] = exp_pca_kmeans_50['Expression K-Means PCA'].map({0:'first', 1:'second', 2:'third', 3:'fourth', 4:'fifth', 5:'sixth', 6:'seventh', 7:'eighth', 8:'ninth', 9:'tenth'})\n",
    "exp_pca_kmeans_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_pca_kmeans_40 = pd.concat([expression.reset_index(drop = True), pd.DataFrame(scores_pca_40)], axis = 1)\n",
    "labels = [i for i in range(0, len(expression.columns))] + ['Component 1']\n",
    "exp_pca_kmeans_40.columns = labels\n",
    "\n",
    "# Add the PCA K-means Clustering labels\n",
    "exp_pca_kmeans_40['Expression K-Means PCA'] = kmeans_pca_40.labels_\n",
    "\n",
    "exp_pca_kmeans_40['Expression'] = exp_pca_kmeans_40['Expression K-Means PCA'].map({0:'first', 1:'second', 2:'third', 3:'fourth', 4:'fifth', 5:'sixth', 6:'seventh'})\n",
    "exp_pca_kmeans_40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the three PCA components with largest variance for 80% variance capture\n",
    "x = exp_pca_kmeans_80['Component 1']\n",
    "y = exp_pca_kmeans_80['Component 2']\n",
    "z = exp_pca_kmeans_80['Component 3']\n",
    "\n",
    "# Axes instance\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = Axes3D(fig)\n",
    "fig.add_axes(ax)\n",
    "\n",
    "# Seaborn colormap\n",
    "cmap = ListedColormap(sns.color_palette(\"husl\", 256).as_hex())\n",
    "\n",
    "# Plot\n",
    "sc = ax.scatter(x, y, z, s=40, c=x, marker='o', cmap=cmap, alpha=1)\n",
    "ax.set_xlabel('Component 1')\n",
    "ax.set_ylabel('Component 2')\n",
    "ax.set_zlabel('Component 3')\n",
    "\n",
    "# Legend\n",
    "plt.legend(*sc.legend_elements(), bbox_to_anchor=(1.05, 1), loc=2)\n",
    "plt.title('Brain Region Clusters by PCA Components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the two PCA components for 50% variance capture\n",
    "x = exp_pca_kmeans_50['Component 1']\n",
    "y = exp_pca_kmeans_50['Component 2']\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x = x, y = y, hue = exp_pca_kmeans_50['Expression'])\n",
    "plt.title('Gene Clusters by PCA Components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the PCA componentfor 40% variance capture\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.stripplot(data = exp_pca_kmeans_40['Component 1'])\n",
    "plt.title('Gene Clusters by PCA Components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nilearn Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_stat_map\n",
    "\n",
    "atlas = abagen.fetch_desikan_killiany()\n",
    "im = nib.load(atlas['image'])\n",
    "\n",
    "display = plot_stat_map(im)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ahba",
   "language": "python",
   "name": "ahba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
